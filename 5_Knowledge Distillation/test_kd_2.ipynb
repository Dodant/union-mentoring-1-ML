{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20a73a59-0918-4b05-8d11-4003233fccb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./data/datasets/ImageNet/train/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26078/2430301599.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mstudent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mimagenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/datasets/ImageNet/train/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/datasets/ImageNet/val/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifarset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagenet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/curly-tribble/py38/lib/python3.8/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, download, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/curly-tribble/py38/lib/python3.8/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/curly-tribble/py38/lib/python3.8/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/curly-tribble/py38/lib/python3.8/site-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m    101\u001b[0m         msg = (\"The archive {} is not present in the root directory or is corrupted. \"\n\u001b[1;32m    102\u001b[0m                \"You need to download it externally and place it in {}.\")\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in ./data/datasets/ImageNet/train/."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "# hyperparameter\n",
    "T = 2.0\n",
    "student_model = 18\n",
    "\n",
    "batch_size = 1024\n",
    "num_workers = 4\n",
    "\n",
    "epochs = 25\n",
    "alpha = 0.7\n",
    "student = 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.244, 0.225]),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(5)\n",
    "])\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# teacher = ResNet50\n",
    "teacher = models.resnet50(pretrained=True).to(device).eval()\n",
    "\n",
    "# student = ResNet18, ResNet34, ResNet50\n",
    "if student_model == 18:\n",
    "    student = models.resnet18(pretrained=False).to(device)\n",
    "elif student_model == 34:\n",
    "    student = models.resnet34(pretrained=False).to(device)\n",
    "elif student_model == 50:\n",
    "    student = models.resnet50(pretrained=False).to(device)\n",
    "    \n",
    "imagenet = datasets.ImageNet('./data/datasets/ImageNet/train/', split='train', transform=transform)\n",
    "testset = datasets.ImageNet('./data/datasets/ImageNet/val/', split='val', transform=transform)\n",
    "trainset, _ = random_split(imagenet, [1000000, len(imagenet) - 1000000])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d590c782-d0ce-48a1-bdd1-51e65438da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistillationLoss(teacher_logit, student_logit, T):\n",
    "    soft_label = F.softmax(teacher_logit / T, dim=1)[0]\n",
    "    soft_prediction = F.log_softmax(student_logit / T, dim=1)[0]\n",
    "    return nn.KLDivLoss()(soft_prediction, soft_label)\n",
    "\n",
    "def StudentLoss(student_logit, hard_label):\n",
    "    hard_label = F.softmax(student_logit, dim=1)[0]\n",
    "    return nn.CrossEntropyLoss()(student_logit, hard_label)\n",
    "\n",
    "def FinalLoss(teacher_logit, student_logit, labels, T, alpha):\n",
    "    return (1. - alpha) * StudentLoss(student_logit, labels) \\\n",
    "            + (alpha * T * T) * DistillationLoss(teacher_logit, student_logit, T)\n",
    "\n",
    "optimizer = optim.Adam(student.parameters(), lr=0.001)\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8ed9eb71-401c-4c73-9e87-de8388689279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config : Student = ResNet18, T = 2.0, alpha = 0.7\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26078/3475939109.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "print(f'Config : Student = ResNet{student_model}, T = {T}, alpha = {alpha}')\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_samples = 0\n",
    "    \n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with amp.autocast():\n",
    "            student_logit = student(inputs)\n",
    "            teacher_logit = teacher(inputs)\n",
    "            loss = FinalLoss(teacher_logit, student_logit, labels, T, alpha)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels.data)\n",
    "        train_samples += len(inputs)\n",
    "    \n",
    "    epoch_loss = train_loss / len(trainloader)\n",
    "    epoch_acc = train_acc.float() / train_samples * 100\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        print(f\"epoch: {epoch + 1} || tl: {epoch_loss:.3f}, ta: {epoch_acc:.2f}%\")\n",
    "\n",
    "print('Training Finished')\n",
    "\n",
    "correct_s, correct_5s, total_s = 0, 0, 0\n",
    "correct_t, correct_5t, total_t = 0, 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # student - top1\n",
    "        outputs_s = student(images)\n",
    "        _, predicted_s = torch.max(outputs_s.data, 1)\n",
    "        total_s += labels.size(0)\n",
    "        correct_s += (predicted_s == labels).sum().item()\n",
    "        # top5\n",
    "        for idx, item in enumerate(labels.view(-1,1)):\n",
    "            if item in torch.topk(outputs_s, 5).indices[idx]:\n",
    "                correct_5s += 1\n",
    "        \n",
    "        # teacher - top1\n",
    "        outputs_t = teacher(images)\n",
    "        _, predicted_t = torch.max(outputs_t.data, 1)\n",
    "        total_t += labels.size(0)\n",
    "        correct_t += (predicted_t == labels).sum().item()\n",
    "        # top5\n",
    "        for idx, item in enumerate(labels.view(-1,1)):\n",
    "            if item in torch.topk(outputs_t, 5).indices[idx]:\n",
    "                correct_5t += 1\n",
    "\n",
    "print(f'Top1 Acc : student - {correct_s*100/total_s:0.1f}% / teacher - {correct_t*100/total_t:0.1f}%')\n",
    "print(f'Top5 Acc : student - {correct_5s*100/total_s:0.1f}% / teacher - {correct_5t*100/total_t:0.1f}%')\n",
    "print('===========================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85bf273-6e52-4784-8b1f-9eccd42e6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './student_' + str(student_model) + '_' + str(T) + '.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "99830214-f6f2-4a45-808e-5e606a443e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000],\n",
      "        [0.7000, 0.5000, 0.2000, 0.3000, 0.4000, 0.1000],\n",
      "        [0.5000, 0.6000, 0.8000, 0.3000, 0.7000, 0.9000]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.Tensor([3, 5, 3])\n",
    "\n",
    "x = torch.Tensor([[.1,.2,.3,.4,.5,.6],\n",
    "                 [.7,.5,.2,.3,.4,.1],\n",
    "                 [.5,.6,.8,.3,.7,.9]])\n",
    "print(x)\n",
    "label.view(-1,1) in torch.topk(x, 3).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8d9e1172-c977-4707-9a6e-5ee3460e281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "\n",
    "for idx, item in enumerate(label.view(-1,1)):\n",
    "    if item in torch.topk(x, 3).indices[idx]:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9accf00d-d99a-49d6-a8b4-54ec5f5a47b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((label.view(-1,1) in torch.topk(x, 3).indices) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc3174-8c90-494c-b841-d6e9b3c8b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
