{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5498312-59f6-4d30-a3a7-d8f74397e216",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.datasets.utils import download_and_extract_archive, extract_archive, verify_str_arg, check_integrity\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from urllib.error import URLError\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import codecs\n",
    "from PIL import Image\n",
    "\n",
    "class myMNIST(VisionDataset):\n",
    "\n",
    "    mirrors = [\n",
    "        'http://yann.lecun.com/exdb/mnist/',\n",
    "        'https://ossci-datasets.s3.amazonaws.com/mnist/',\n",
    "    ]\n",
    "\n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"f68b3c2dcbeaaa9fbdd348bbdeb94873\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"d53e105ee54ea40749a09fcbcd1e9432\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"9fb629c4189551a2d022fa330f9573f3\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"ec29112dd5afa0611ce80d1b7f02629c\")\n",
    "    ]\n",
    "\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "    classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four',\n",
    "               '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n",
    "\n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        warnings.warn(\"train_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def test_labels(self):\n",
    "        warnings.warn(\"test_labels has been renamed targets\")\n",
    "        return self.targets\n",
    "\n",
    "    @property\n",
    "    def train_data(self):\n",
    "        warnings.warn(\"train_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    @property\n",
    "    def test_data(self):\n",
    "        warnings.warn(\"test_data has been renamed data\")\n",
    "        return self.data\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "        super(myMNIST, self).__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.train = train  # training set or test set\n",
    "\n",
    "        if self._check_legacy_exist():\n",
    "            self.data, self.targets = self._load_legacy_data()\n",
    "            return\n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Dataset not found.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        self.data, self.targets = self._load_data()\n",
    "        \n",
    "        import random \n",
    "        imbalance_list = random.sample(range(0,10), 5)\n",
    "\n",
    "        new_data = []\n",
    "        new_target = []\n",
    "\n",
    "        for i in range(len(self.targets)):\n",
    "            if self.targets[i] in imbalance_list:\n",
    "                if random.random() >= 0.9:\n",
    "                    new_data.append(self.data[i])\n",
    "                    new_target.append(self.targets[i])\n",
    "            else:\n",
    "                new_data.append(self.data[i])\n",
    "                new_target.append(self.targets[i])\n",
    "\n",
    "        self.data = new_data\n",
    "        self.targets = new_target\n",
    "\n",
    "\n",
    "    def _check_legacy_exist(self):\n",
    "        processed_folder_exists = os.path.exists(self.processed_folder)\n",
    "        if not processed_folder_exists:\n",
    "            return False\n",
    "\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.processed_folder, file)) for file in (self.training_file, self.test_file)\n",
    "        )\n",
    "\n",
    "    def _load_legacy_data(self):\n",
    "        # This is for BC only. We no longer cache the data in a custom binary, but simply read from the raw data\n",
    "        # directly.\n",
    "        data_file = self.training_file if self.train else self.test_file\n",
    "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
    "\n",
    "    def _load_data(self):\n",
    "        image_file = f\"{'train' if self.train else 't10k'}-images-idx3-ubyte\"\n",
    "        data = read_image_file(os.path.join(self.raw_folder, image_file))\n",
    "\n",
    "        label_file = f\"{'train' if self.train else 't10k'}-labels-idx1-ubyte\"\n",
    "        targets = read_label_file(os.path.join(self.raw_folder, label_file))\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def processed_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'processed')\n",
    "\n",
    "    @property\n",
    "    def class_to_idx(self) -> Dict[str, int]:\n",
    "        return {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def _check_exists(self) -> bool:\n",
    "        return all(\n",
    "            check_integrity(os.path.join(self.raw_folder, os.path.splitext(os.path.basename(url))[0]))\n",
    "            for url, _ in self.resources\n",
    "        )\n",
    "\n",
    "    def download(self) -> None:\n",
    "        \"\"\"Download the MNIST data if it doesn't exist already.\"\"\"\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "\n",
    "        # download files\n",
    "        for filename, md5 in self.resources:\n",
    "            for mirror in self.mirrors:\n",
    "                url = \"{}{}\".format(mirror, filename)\n",
    "                try:\n",
    "                    print(\"Downloading {}\".format(url))\n",
    "                    download_and_extract_archive(\n",
    "                        url, download_root=self.raw_folder,\n",
    "                        filename=filename,\n",
    "                        md5=md5\n",
    "                    )\n",
    "                except URLError as error:\n",
    "                    print(\n",
    "                        \"Failed to download (trying next):\\n{}\".format(error)\n",
    "                    )\n",
    "                    continue\n",
    "                finally:\n",
    "                    print()\n",
    "                break\n",
    "            else:\n",
    "                raise RuntimeError(\"Error downloading {}\".format(filename))\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")\n",
    "    \n",
    "\n",
    "class myFashionMNIST(myMNIST):\n",
    "    mirrors = [\n",
    "        \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/\"\n",
    "    ]\n",
    "\n",
    "    resources = [\n",
    "        (\"train-images-idx3-ubyte.gz\", \"8d4fb7e6c68d591d4c3dfef9ec88bf0d\"),\n",
    "        (\"train-labels-idx1-ubyte.gz\", \"25c81989df183df01b3e8a0aad5dffbe\"),\n",
    "        (\"t10k-images-idx3-ubyte.gz\", \"bef4ecab320f06d8554ea6380940ec79\"),\n",
    "        (\"t10k-labels-idx1-ubyte.gz\", \"bb300cfdad3c16e7a12a480ee83cd310\")\n",
    "    ]\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "def get_int(b: bytes) -> int:\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "    \n",
    "SN3_PASCALVINCENT_TYPEMAP = {\n",
    "    8: (torch.uint8, np.uint8, np.uint8),\n",
    "    9: (torch.int8, np.int8, np.int8),\n",
    "    11: (torch.int16, np.dtype('>i2'), 'i2'),\n",
    "    12: (torch.int32, np.dtype('>i4'), 'i4'),\n",
    "    13: (torch.float32, np.dtype('>f4'), 'f4'),\n",
    "    14: (torch.float64, np.dtype('>f8'), 'f8')\n",
    "}\n",
    "\n",
    "    \n",
    "def read_image_file(path: str) -> torch.Tensor:\n",
    "    x = read_sn3_pascalvincent_tensor(path, strict=False)\n",
    "    assert(x.dtype == torch.uint8)\n",
    "    assert(x.ndimension() == 3)\n",
    "    return x\n",
    "\n",
    "\n",
    "def read_label_file(path: str) -> torch.Tensor:\n",
    "    x = read_sn3_pascalvincent_tensor(path, strict=False)\n",
    "    assert(x.dtype == torch.uint8)\n",
    "    assert(x.ndimension() == 1)\n",
    "    return x.long()\n",
    "\n",
    "\n",
    "def read_sn3_pascalvincent_tensor(path: str, strict: bool = True) -> torch.Tensor:\n",
    "    \"\"\"Read a SN3 file in \"Pascal Vincent\" format (Lush file 'libidx/idx-io.lsh').\n",
    "       Argument may be a filename, compressed filename, or file object.\n",
    "    \"\"\"\n",
    "    # read\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    # parse\n",
    "    magic = get_int(data[0:4])\n",
    "    nd = magic % 256\n",
    "    ty = magic // 256\n",
    "    assert 1 <= nd <= 3\n",
    "    assert 8 <= ty <= 14\n",
    "    m = SN3_PASCALVINCENT_TYPEMAP[ty]\n",
    "    s = [get_int(data[4 * (i + 1): 4 * (i + 2)]) for i in range(nd)]\n",
    "    parsed = np.frombuffer(data, dtype=m[1], offset=(4 * (nd + 1)))\n",
    "    assert parsed.shape[0] == np.prod(s) or not strict\n",
    "    return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9298f353-b628-4013-9006-19ef509c18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((64, 64))])\n",
    "\n",
    "# mymnist_trainset = myMNIST(root='./data1', train=True, download=True)\n",
    "# mymnist_trainloader = torch.utils.data.DataLoader(mymnist_trainset, batch_size=batch_size, shuffle=True, num_workers=2 ,pin_memory=True)\n",
    "\n",
    "myfmnist_trainset = myFashionMNIST(root='./data1', train=True, download=True, transform=transform)\n",
    "myfmnist_trainloader = torch.utils.data.DataLoader(myfmnist_trainset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2110843e-f660-4916-8e46-245c2598e6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33024\n"
     ]
    }
   ],
   "source": [
    "# print(len(mymnist_trainset.data))\n",
    "print(len(myfmnist_trainset.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfba4bce-2844-47a7-8514-3899543e9840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000, 662, 6000, 6000, 616, 604, 6000, 6000, 596, 546]\n",
      "28 28\n"
     ]
    }
   ],
   "source": [
    "# num_of_class_MNIST = [0,0,0,0,0,0,0,0,0,0]\n",
    "num_of_class_fMNIST = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# for i in mymnist_trainset.targets:\n",
    "#     num_of_class_MNIST[i] += 1\n",
    "for i in myfmnist_trainset.targets:\n",
    "    num_of_class_fMNIST[i] += 1\n",
    "    \n",
    "# print(num_of_class_MNIST)\n",
    "print(num_of_class_fMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79c6aea3-c3a2-4378-b85c-4f1966dfa5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mymnist_testset = torchvision.datasets.MNIST(root='./data1', train=False, download=True)\n",
    "# mymnist_testloader = torch.utils.data.DataLoader(mymnist_testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "myfmnist_testset = torchvision.datasets.FashionMNIST(root='./data1', train=False, download=True, transform=transform)\n",
    "myfmnist_testloader = torch.utils.data.DataLoader(myfmnist_testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8d7f0df-15be-43c1-82f0-71ae29225347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc4): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc5): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 5)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 5)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(128, 128, 3)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 128)\n",
    "        self.fc5 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1) # 배치를 제외한 모든 차원을 평탄화(flatten)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2317e4f2-59ed-46f1-acc3-f1797d65ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4af975de-d3f4-46ce-a8a7-bf18a2671a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, train_acc_history = [], []\n",
    "# valid_loss_history, valid_acc_history = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24cfee6e-7323-45b1-b21b-ebb9b7f7ba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 || tl: 1.452 | ta: 41.945\n",
      "epoch: 2 || tl: 0.731 | ta: 70.521\n",
      "epoch: 3 || tl: 0.612 | ta: 74.397\n",
      "epoch: 4 || tl: 0.547 | ta: 78.613\n",
      "epoch: 5 || tl: 0.492 | ta: 81.365\n",
      "epoch: 6 || tl: 0.453 | ta: 82.855\n",
      "epoch: 7 || tl: 0.421 | ta: 84.166\n",
      "epoch: 8 || tl: 0.398 | ta: 85.029\n",
      "epoch: 9 || tl: 0.372 | ta: 86.101\n",
      "epoch: 10 || tl: 0.353 | ta: 86.888\n",
      "epoch: 11 || tl: 0.336 | ta: 87.536\n",
      "epoch: 12 || tl: 0.316 | ta: 88.269\n",
      "epoch: 13 || tl: 0.304 | ta: 88.602\n",
      "epoch: 14 || tl: 0.287 | ta: 89.393\n",
      "epoch: 15 || tl: 0.273 | ta: 89.907\n",
      "epoch: 16 || tl: 0.258 | ta: 90.583\n",
      "epoch: 17 || tl: 0.247 | ta: 90.879\n",
      "epoch: 18 || tl: 0.230 | ta: 91.470\n",
      "epoch: 19 || tl: 0.216 | ta: 92.103\n",
      "epoch: 20 || tl: 0.203 | ta: 92.569\n",
      "epoch: 21 || tl: 0.189 | ta: 93.057\n",
      "epoch: 22 || tl: 0.174 | ta: 93.590\n",
      "epoch: 23 || tl: 0.162 | ta: 94.041\n",
      "epoch: 24 || tl: 0.150 | ta: 94.622\n",
      "epoch: 25 || tl: 0.137 | ta: 94.922\n",
      "epoch: 26 || tl: 0.126 | ta: 95.512\n",
      "epoch: 27 || tl: 0.117 | ta: 95.927\n",
      "epoch: 28 || tl: 0.104 | ta: 96.160\n",
      "epoch: 29 || tl: 0.096 | ta: 96.487\n",
      "epoch: 30 || tl: 0.090 | ta: 96.757\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "for epoch in range(epochs):   # 데이터셋을 수차례 반복합니다.\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    \n",
    "    train_samples = 0\n",
    "    valid_samples = 0\n",
    "    \n",
    "    for inputs, labels in myfmnist_trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 변화도(Gradient) 매개변수를 0으로 만들고\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels.data)\n",
    "        train_samples += len(inputs)\n",
    "    \n",
    "#     else:\n",
    "#         # 훈련팔 필요가 없으므로 메모리 절약\n",
    "#         with torch.no_grad():\n",
    "#             for valid_input, valid_label in valid_loader:\n",
    "#                 valid_input, valid_label = valid_input.to(device), valid_label.to(device)\n",
    "#                 valid_outputs = net(valid_input)\n",
    "#                 valid_loss = criterion(valid_outputs, valid_label)\n",
    "\n",
    "#                 _, valid_preds = torch.max(valid_outputs, 1)\n",
    "#                 valid_loss += valid_loss.item()\n",
    "#                 valid_acc += torch.sum(valid_preds == valid_label.data)\n",
    "#                 valid_samples += len(valid_input)\n",
    "                \n",
    "    epoch_loss = train_loss / len(myfmnist_trainloader)\n",
    "    epoch_acc = train_acc.float() / train_samples * 100\n",
    "    train_loss_history.append(epoch_loss)\n",
    "    train_acc_history.append(epoch_acc)\n",
    "\n",
    "#     valid_epoch_loss = valid_loss * 10 / len(valid_loader)\n",
    "#     valid_epoch_acc = valid_acc.float() / valid_samples * 100\n",
    "#     valid_loss_history.append(valid_epoch_loss)\n",
    "#     valid_acc_history.append(valid_epoch_acc)\n",
    "\n",
    "#     if (epoch + 1) % 5 == 0:\n",
    "    print(f\"epoch: {epoch + 1} || tl: {epoch_loss:.3f} | ta: {epoch_acc:.3f}\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2ad3cd5-b785-448f-8fa1-3eb8d155520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요가 없습니다\n",
    "with torch.no_grad():\n",
    "    for images, labels in myfmnist_testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 신경망에 이미지를 통과시켜 출력을 계산합니다\n",
    "        outputs = net(images)\n",
    "        # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택하겠습니다\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57ca8a2d-e6f4-403b-84f8-980f6014e03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class T-shirt/top is: 84.3 %\n",
      "Accuracy for class Trouser is: 95.2 %\n",
      "Accuracy for class Pullover is: 90.9 %\n",
      "Accuracy for class Dress is: 94.3 %\n",
      "Accuracy for class Coat  is: 51.6 %\n",
      "Accuracy for class Sandal is: 93.0 %\n",
      "Accuracy for class Shirt is: 77.6 %\n",
      "Accuracy for class Sneaker is: 98.7 %\n",
      "Accuracy for class Bag   is: 90.6 %\n",
      "Accuracy for class Ankle boot is: 90.3 %\n"
     ]
    }
   ],
   "source": [
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "               'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# 변화도는 여전히 필요하지 않습니다\n",
    "with torch.no_grad():\n",
    "    for images, labels in myfmnist_testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# 각 분류별 정확도(accuracy)를 출력합니다\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dce6010-b7ea-4791-ad9a-7acf74ee199e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000, 662, 6000, 6000, 616, 604, 6000, 6000, 596, 546]\n"
     ]
    }
   ],
   "source": [
    "# num_of_class_MNIST = [0,0,0,0,0,0,0,0,0,0]\n",
    "num_of_class_fMNIST = [0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "# for i in mymnist_trainset.targets:\n",
    "#     num_of_class_MNIST[i] += 1\n",
    "for i in myfmnist_trainset.targets:\n",
    "    num_of_class_fMNIST[i] += 1\n",
    "    \n",
    "# print(num_of_class_MNIST)\n",
    "print(num_of_class_fMNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ecf88-2767-4623-8ea0-98b1fc5c512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(14,5))\n",
    "# plt.subplot(1, 2, 1)  \n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.plot(valid_loss_history,label=\"val\")\n",
    "# plt.plot(train_loss_history,label=\"train\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2) \n",
    "# plt.title(\"Training and Validation Acc\")\n",
    "# plt.plot(valid_acc_history,label=\"val\")\n",
    "# plt.plot(train_acc_history,label=\"train\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Acc\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e8fc6-88fb-4dde-a3a5-eb6e455d2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './myfmnist_net.pth'\n",
    "torch.save(net.state_dict(), PATH)\n",
    "\n",
    "# net = Net()\n",
    "# net.load_state_dict(torch.load(PATH))\n",
    "# net.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03f64de78dec4ada81332312b747156b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f702bd98b5df4f1dbeefc00d707a2e43",
       "style": "IPY_MODEL_5198edd7d8eb4f368f32615bb0a6af04"
      }
     },
     "0bbd368091894af89e89930e080974ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "0be0e505228f4016ac563c0932186847": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "0e248a20c67a4efcb006ed894740cd75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "167c37eaf41341df81e0deb202273f31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b9ad23ecddd644e2adc5d4c7d36ca358",
       "style": "IPY_MODEL_0e248a20c67a4efcb006ed894740cd75",
       "value": " 26427392/? [00:50&lt;00:00, 1690123.58it/s]"
      }
     },
     "17cc0d7d22f04435b152465471316f3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "info",
       "layout": "IPY_MODEL_0bbd368091894af89e89930e080974ff",
       "max": 1,
       "style": "IPY_MODEL_a28fb707c1ef48ada9601518d68ef796",
       "value": 1
      }
     },
     "1957cfc396274ae592801a75e2930157": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1b1852ab74fe473ba519567bf6ee3ce4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6367e9acb6604ec4988fd4a1369d4363",
        "IPY_MODEL_373118ffd72d473c92ebef80af01a2b9",
        "IPY_MODEL_35dbbd2dbe2e4d93a40e904064176843"
       ],
       "layout": "IPY_MODEL_1b87f109986547ba83dcbcb58bf3436f"
      }
     },
     "1b87f109986547ba83dcbcb58bf3436f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2a698a09c3664791961f782f5a7d4d85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5efa4de88f434871be9db9de1a245a49",
       "style": "IPY_MODEL_e12214eeac18431ba4ffb76486888419",
       "value": " 32768/? [00:17&lt;00:00, 57132.54it/s]"
      }
     },
     "2e575bc14fb7423caf35180381359fbe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "31f0da7656ba41b89c23786c813bc64d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f65f9ca621b3401e94d79e6e373ae4d7",
        "IPY_MODEL_d62b80b48edf4bfdaf415da259401bdf",
        "IPY_MODEL_167c37eaf41341df81e0deb202273f31"
       ],
       "layout": "IPY_MODEL_a62fcfe6b2b64ab1b6cb20a47a6ce65c"
      }
     },
     "329d60139ccf47bdb8523ccda86d85cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "35dbbd2dbe2e4d93a40e904064176843": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_41d3cb65f7574d708a8e2a25cc5c6b51",
       "style": "IPY_MODEL_c8705b4875fd48b7b173535e7edceb96",
       "value": " 0/5148 [00:00&lt;?, ?it/s]"
      }
     },
     "373118ffd72d473c92ebef80af01a2b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "info",
       "layout": "IPY_MODEL_b2a0b82a59ff4041a3836c5d0a3d37a1",
       "max": 1,
       "style": "IPY_MODEL_dd39cad354b14fd1befaf163b23882fc"
      }
     },
     "3ca7a19ad369418e8a9eeb66cec97bc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1957cfc396274ae592801a75e2930157",
       "style": "IPY_MODEL_329d60139ccf47bdb8523ccda86d85cb",
       "value": " 4423680/? [00:26&lt;00:00, 1121015.89it/s]"
      }
     },
     "41c7eb6048df465db3fcc95c8f7602b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_03f64de78dec4ada81332312b747156b",
        "IPY_MODEL_e0e0ef7173ff42aeb117e22b61c05638",
        "IPY_MODEL_3ca7a19ad369418e8a9eeb66cec97bc9"
       ],
       "layout": "IPY_MODEL_710225b0c0b240fc86f966a871f9a2c1"
      }
     },
     "41d3cb65f7574d708a8e2a25cc5c6b51": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "44d9c277bb434167bd90c93eb63171ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5198edd7d8eb4f368f32615bb0a6af04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5efa4de88f434871be9db9de1a245a49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6367e9acb6604ec4988fd4a1369d4363": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f250a6c5ed9846dfb129a0d3ab33ed1b",
       "style": "IPY_MODEL_71437cb83b83444190964adf75f70520",
       "value": "  0%"
      }
     },
     "6c42e5cf638f4e3faa3154213a858bc5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_73afb8f294f24f3cbad4179d0ea52b04",
       "style": "IPY_MODEL_0be0e505228f4016ac563c0932186847"
      }
     },
     "6f3865d724f649db89d983762f406b1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_6c42e5cf638f4e3faa3154213a858bc5",
        "IPY_MODEL_17cc0d7d22f04435b152465471316f3b",
        "IPY_MODEL_2a698a09c3664791961f782f5a7d4d85"
       ],
       "layout": "IPY_MODEL_2e575bc14fb7423caf35180381359fbe"
      }
     },
     "710225b0c0b240fc86f966a871f9a2c1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "71437cb83b83444190964adf75f70520": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "73afb8f294f24f3cbad4179d0ea52b04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7d1b8b3d2cde41149147a6864f24540f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a28fb707c1ef48ada9601518d68ef796": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a62fcfe6b2b64ab1b6cb20a47a6ce65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b2a0b82a59ff4041a3836c5d0a3d37a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "b9ad23ecddd644e2adc5d4c7d36ca358": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c8705b4875fd48b7b173535e7edceb96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "c939c6e33099476080359b3b7d221862": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d62b80b48edf4bfdaf415da259401bdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "info",
       "layout": "IPY_MODEL_fd59ad56854940ccb9802217c213162a",
       "max": 1,
       "style": "IPY_MODEL_44d9c277bb434167bd90c93eb63171ef",
       "value": 1
      }
     },
     "dd39cad354b14fd1befaf163b23882fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e0e0ef7173ff42aeb117e22b61c05638": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "info",
       "layout": "IPY_MODEL_e87708536918417486303a825faa68c6",
       "max": 1,
       "style": "IPY_MODEL_c939c6e33099476080359b3b7d221862",
       "value": 1
      }
     },
     "e12214eeac18431ba4ffb76486888419": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e87708536918417486303a825faa68c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     },
     "f250a6c5ed9846dfb129a0d3ab33ed1b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f65f9ca621b3401e94d79e6e373ae4d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7d1b8b3d2cde41149147a6864f24540f",
       "style": "IPY_MODEL_f8fb255c231d4add85e77d6975e263ba"
      }
     },
     "f702bd98b5df4f1dbeefc00d707a2e43": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f8fb255c231d4add85e77d6975e263ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fd59ad56854940ccb9802217c213162a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "20px"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
