{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47529e2-7dc3-4e0e-bfff-1105614fdb33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import argparse\n",
    "import math\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((64, 64)),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(32, 64, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Conv2d(512, 1024, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e80045-c194-4c74-9ad7-53e6a71904c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "PATH = './cifar_net.pth'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7694da-bba5-4098-98e6-78fbf88ad7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.weight\n",
      "0.0029217947740107775\n",
      "layer1.3.weight\n",
      "0.0006999003235250711\n",
      "layer2.0.weight\n",
      "0.0005954368971288204\n",
      "layer2.3.weight\n",
      "0.0005173255340196192\n",
      "layer3.0.weight\n",
      "0.00035453165764920413\n",
      "layer3.3.weight\n",
      "0.00021319415827747434\n",
      "fc1.weight\n",
      "0.00040379914571531117\n",
      "fc2.weight\n",
      "0.0005659299204126\n",
      "fc3.weight\n",
      "0.0008856855565682054\n",
      "fc4.weight\n",
      "0.004978759214282036\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "total_W = 0\n",
    "total_Z = 0\n",
    "\n",
    "layers = ['layer1.0.weight','layer1.3.weight',\n",
    "              'layer2.0.weight','layer2.3.weight',\n",
    "              'layer3.0.weight','layer3.3.weight',\n",
    "              'fc1.weight','fc2.weight','fc3.weight','fc4.weight']\n",
    "\n",
    "for layer in layers:\n",
    "    target = net.state_dict()[layer].data\n",
    "    flatten = target.view(-1)\n",
    "    boundary = abs(sorted(flatten, key=lambda a: torch.abs(a))[math.ceil(len(flatten) * p / 100)].item())\n",
    "    lower = -boundary < target\n",
    "    upper = target < boundary\n",
    "    \n",
    "    target = torch.where(torch.logical_not(torch.logical_and(lower, upper)), target, torch.cuda.FloatTensor([0]))\n",
    "    net.state_dict()[layer].data.copy_(target)\n",
    "    \n",
    "    total_Z += len(net.state_dict()[layer][net.state_dict()[layer].data == 0.0])\n",
    "    total_W += reduce(lambda x,y: x*y, net.state_dict()[layer].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dda69b-af78-4d41-a6e2-9d69840f2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.01\n",
      "Trainset Acc:  10.0%\n",
      "Testset Acc:  10.0%\n",
      "Number of Zeros: 6815969\n",
      "Number of Weights: 6884832\n",
      "Pruned Ratio:  99.0%\n"
     ]
    }
   ],
   "source": [
    "train_correct, train_total = 0, 0\n",
    "test_correct, test_total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print(f'p = {p / 100}')\n",
    "print(f'Trainset Acc: {100 * train_correct / train_total: .1f}%')\n",
    "print(f'Testset Acc: {100 * test_correct / test_total: .1f}%')\n",
    "print(f'Number of Zeros: {total_Z}')\n",
    "print(f'Number of Weights: {total_W}')\n",
    "print(f'Pruned Ratio: {total_Z / total_W * 100: .1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ae9dcf1-8ab5-4de7-bf8e-26ab70d706ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False],\n",
      "        [ True,  True]])\n",
      "tensor([[-1,  0],\n",
      "        [ 3, -4]])\n",
      "tensor([[-1,  0],\n",
      "        [ 3, -4]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[-1,2],\n",
    "                [3,-4]])\n",
    "print(x != 2)\n",
    "print(x := torch.where(x != 2, x, 0))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d30ee7b-589e-456d-854b-d9246757326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  0,  3, -4])\n",
      "1\n",
      "tensor([ True,  True,  True, False])\n",
      "tensor([ True,  True, False,  True])\n",
      "tensor([False, False,  True,  True])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  3, -4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.view(-1)\n",
    "print(x)\n",
    "y = sorted(x, key=lambda a: torch.abs(a))[1].item()\n",
    "print(abs(y))\n",
    "# torch.where(-1 <= x, x, torch.FloatTensor([0.0]))\n",
    "print(-1 <= x)\n",
    "print(x <= 1)\n",
    "print(torch.logical_not(torch.logical_and(-abs(y) <= x, x <= abs(y))))\n",
    "torch.where(torch.logical_not(torch.logical_and(-abs(y) <= x, x <= abs(y))), x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9f38eba-fbc9-48ae-9f59-55f4b34a39b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592a5fb-1a01-409f-8ada-46dc03418258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b7e18-cfeb-41e3-94f8-626faef0ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net_' + str(p) + '.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
